# Traffic Flow Prediction using Spatio-Temporal Graph Neural Networks

A PyTorch implementation of a Spatio-Temporal Graph Neural Network (ST-GNN) for traffic flow prediction on the PEMS-BAY dataset.

## ğŸ“‹ Project Overview

This project implements a state-of-the-art GNN model that:
- **Captures spatial dependencies** between connected road sensors using Graph Convolution
- **Models temporal patterns** using Temporal Convolutional Networks with dilated convolutions
- **Predicts future traffic conditions** (speed/flow) for multiple time steps ahead

## ğŸ—ï¸ Architecture

**Spatio-Temporal GNN (ST-GNN)**
- **Graph Convolution Layer**: Learns how traffic propagates through the road network
- **Temporal Convolutional Network**: Captures traffic dynamics over time with dilated causal convolutions
- **Multi-layer Spatio-Temporal Blocks**: Combines spatial and temporal learning
- **Multi-step Prediction**: Forecasts traffic for next 12 time steps (1 hour)

## ğŸ“Š Dataset

**PEMS-BAY** - Bay Area traffic data
- 325 sensors (nodes in the graph)
- 5-minute intervals
- Traffic speed measurements
- Adjacency matrix (road connectivity)

Your dataset files:
```
data/
â”œâ”€â”€ pems-bay.h5          # Traffic speed data
â”œâ”€â”€ pems-bay-meta.h5     # Metadata
â””â”€â”€ adj_mx_bay.pkl       # Adjacency matrix (graph structure)
```

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Prepare Your Data

Make sure your data is in the correct folder:
```
E:/sonia (E_)/roehampton university/sem 2/data science/data visulization data/
```

Or update the `DATA_DIR` path in the scripts.

### 3. Train the Model

```bash
python train.py
```

This will:
- Load and preprocess PEMS-BAY data
- Create train/validation/test splits (70/10/20)
- Train the ST-GNN model for 50 epochs
- Save the best model to `best_st_gnn.pth`
- Generate training curves in `training_curves.png`

**Training Configuration:**
- Sequence length: 12 steps (1 hour input)
- Prediction length: 12 steps (1 hour ahead)
- Batch size: 32
- Hidden channels: 64
- Number of layers: 3
- Learning rate: 0.001

### 4. Visualize Results

```bash
python visualize.py
```

This generates:
- `predictions.png` - Prediction vs ground truth for sample sensors
- `error_distribution.png` - Error histogram and box plot
- `spatial_graph.png` - Adjacency matrix heatmap
- `error_by_time.png` - How error increases over prediction horizon

## ğŸ“ Project Structure

```
traffic-gnn-project/
â”‚
â”œâ”€â”€ data_loader.py       # Data loading and preprocessing
â”œâ”€â”€ st_gnn.py           # ST-GNN model architecture
â”œâ”€â”€ train.py            # Training pipeline
â”œâ”€â”€ visualize.py        # Visualization and analysis
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ README.md          # This file
â”‚
â”œâ”€â”€ best_st_gnn.pth     # Saved best model (after training)
â”œâ”€â”€ training_curves.png # Training history plots
â””â”€â”€ predictions.png     # Visualization outputs
```

## ğŸ”¬ Model Components

### 1. Graph Convolution Layer
```python
GraphConvolution(in_features, out_features)
```
- Learns spatial dependencies between connected road sensors
- Uses symmetric normalization: D^(-1/2) * A * D^(-1/2)

### 2. Temporal Convolutional Network
```python
TemporalConvNet(in_channels, out_channels, kernel_size, dilation)
```
- Dilated causal convolutions (only looks at past, not future)
- Exponentially increasing dilation rates (1, 2, 4, 8...)
- Captures both short-term and long-term temporal patterns

### 3. Spatio-Temporal Block
```python
SpatioTemporalBlock(in_channels, out_channels, num_nodes)
```
- Combines graph convolution + temporal convolution
- Residual connections for better gradient flow
- Layer normalization for training stability

### 4. Full ST-GNN Model
```python
STGNN(num_nodes, hidden_channels, num_layers, pred_len)
```
- Stacks multiple ST blocks with increasing dilation
- Multi-step prediction head
- ~500K trainable parameters

## ğŸ“Š Evaluation Metrics

The model is evaluated using:
- **MAE** (Mean Absolute Error) - Average prediction error
- **RMSE** (Root Mean Squared Error) - Penalizes large errors
- **MAPE** (Mean Absolute Percentage Error) - Relative error

## ğŸ¯ Expected Results

Based on the PEMS-BAY benchmark:
- **MAE**: ~1.5-2.0 (normalized scale)
- **RMSE**: ~3.0-4.0
- **MAPE**: ~3-5%

Results will vary based on:
- Number of training epochs
- Model complexity (layers, hidden channels)
- Hyperparameter tuning

## ğŸ”§ Customization

### Change Prediction Horizon

In `train.py`:
```python
PRED_LEN = 6  # Predict 30 minutes ahead (6 Ã— 5 min)
```

### Adjust Model Size

```python
HIDDEN_CHANNELS = 128  # Larger model
NUM_LAYERS = 4         # Deeper network
```

### Modify Training

```python
EPOCHS = 100           # Train longer
BATCH_SIZE = 64        # Larger batches
LEARNING_RATE = 0.0005 # Fine-tune learning rate
```

## ğŸ“ˆ Understanding the Results

### 1. Training Curves
- **Train vs Val Loss**: Check for overfitting (val loss increasing)
- **MAE/RMSE/MAPE**: Lower is better
- Convergence typically happens around epoch 30-40

### 2. Prediction Visualization
- Blue line: Input sequence (what model sees)
- Green line: Ground truth future
- Red dashed: Model prediction
- Good predictions closely follow ground truth

### 3. Error Analysis
- Error increases with prediction horizon (expected)
- First few steps: lowest error
- Later steps: higher uncertainty

### 4. Spatial Graph
- Shows which roads are connected
- Denser connections = more spatial correlation
- Model learns to propagate traffic information through these connections

## ğŸ“ For Your Project Report

### Key Points to Highlight:

1. **Problem Statement**
   - Multi-node, multi-step traffic forecasting
   - Both spatial (road network) and temporal (time series) dependencies

2. **Why GNN?**
   - Roads are naturally a graph structure
   - Traditional methods treat sensors independently (wrong assumption)
   - GNN models traffic as a connected system (realistic)

3. **Architecture Decisions**
   - Graph convolution: Captures spatial propagation
   - Dilated temporal CNN: Captures long-range temporal patterns
   - Combined: Learns spatio-temporal patterns jointly

4. **Results Interpretation**
   - Compare with baselines (Historical Average, LSTM)
   - Show that spatial modeling improves accuracy
   - Analyze error patterns (by time, by location, by traffic condition)

5. **Future Work**
   - Incorporate external features (weather, events)
   - Attention mechanisms
   - Adaptive graph learning

## ğŸ› Troubleshooting

### Out of Memory Error
- Reduce `BATCH_SIZE` to 16 or 8
- Reduce `HIDDEN_CHANNELS` to 32
- Reduce `NUM_LAYERS` to 2

### Data Loading Issues
- Check file paths are correct
- Verify H5 file structure: `h5py.File('pems-bay.h5', 'r').keys()`
- Ensure pickle file can be loaded

### Slow Training
- Use GPU if available (automatic in code)
- Reduce sequence length or prediction length
- Use fewer ST blocks

## ğŸ“š References

1. **DCRNN** (ICLR 2018): Diffusion Convolutional Recurrent Neural Network
2. **Graph WaveNet** (IJCAI 2019): Adaptive Graph Convolution + Dilated CNN
3. **GMAN** (AAAI 2020): Graph Multi-Attention Network

## ğŸ’¡ Tips for Success

1. **Start Small**: Train for 10 epochs first to verify everything works
2. **Monitor Training**: Watch for overfitting (val loss increasing)
3. **Visualize Early**: Check predictions after 5-10 epochs
4. **Compare Baselines**: Run simple LSTM to show GNN improvement
5. **Document Everything**: Save plots, metrics, and model checkpoints

## âœ¨ Good Luck!

You now have a complete, working ST-GNN implementation for traffic prediction. The code is modular, well-documented, and ready to run. Focus on understanding the results and explaining why the model works!

---

**Contact**: If you need help, check the code comments or refer to the original papers.